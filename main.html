<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Fast SIMD-Based Chunking Algorithm</title>
    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
    <link rel="stylesheet" href="css/override_white.css" id="theme">
    <link rel="stylesheet" href="css/pygment.css">
    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>

  <body>
    <div class="reveal">
      <div class="slides" style="font-size:72px;">

<!----------------------------------------------------------
  This is the actual presentation,
  so the heck with keeping the previous indentation!
  This part is reindented from 0! 
------------------------------------------------------------>
<div class="footermiddle">Fast SIMD-Based Chunking Algorithm</div>
<div class="footerleft">PSC 2019-Aug-27</div>
<div class="footerright">Johnny Dude</div>

<section>
  <section>
    <div>
      <h1>Fast SIMD-Based Chunking Algorithm</h1>
    </div>
    <div>
      <b>Yehonatan Dude, Michael Hirsch, Yair Toaff</b>
    </div>
    <div>
      <p><img src="img/toganetworks.png"></img></p>
      <p><h2>PSC 2019</h2></p>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>I will present today A work Michael Hirsch, Yair Toaff, and I did in Toga Networks</p>
      <p>As a part of overall performance improvement of a deduplication engine.</p>
      <p>Resulted in a new chunking algorithm.</p>
    </aside>
  </section>
</section>


<section>
  <h3><em>Outline</em></h3>
  <section>
    <div>
      <ol>
        <li>Background</li>
        <li>Chunking Problem</li>
        <li>Traditional Solutions</li>
        <li>Our Solution</li>
        <li>Future Work</li>
      </ol>
    </div>
  </section>
</section>


<section>
  <h3><em>Background - Deduplication</em></h3>
  <section>
    <div>
      <h4>
        Deduplication is a technique for eliminating<br/>
        duplicate copies of repeating data.<br/>
      </h4>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>Unlike compression its intent is to
      inspect large volumes of data
      and identify large sections.</p>
    </aside>
  </section>

  <section>
    <h4>Deduplication process in a nutshell</h4>
    <div>
      <ol>
        <li>Divide into chunks</li>
        <li>Calculate the chunks' hashes</li>
        <li>Store chunks uniquely</li>
      </ol>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>We have a repository and we want to store new data.</p>
    </aside>
  </section>

  <section data-background="img/page_13.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>same user or different users.</p>
      <p>It can be of any size.</p>
      <p>It can be processed in any order or parallel.</p>
    </aside>
  </section>

  <section data-background="img/page_14a.svg" data-background-size="60%">
    <div>
    </div>
    <aside class="notes">
      <p>Again, the chunks as well can be of any size.</p>
      <p>Same color means same data</p>
    </aside>
  </section>

  <section data-background="img/page_14b.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>Our repository may look like this.</p>
      <p>Chunked stored or managed uniquely.</p>
      <p>Some kind of index of hashes.</p>
      <p>And some recipea for recovering the data.</p>
    </aside>
  </section>
</section>


<section>
  <h3><em>Background - Chunking Methods</em></h3>
  <section>
    <h4>How to chunk the input data</h4>
    <div>
      <ol>
        <li>Simple - fixed size.</li>
        <li>Content aware - files, objects, applications.</li>
        <li>Content sensitive - rolling hash.</li>
      </ol>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>The main reasons for using a simple approach is lack of resources.</p>
      <p>This should be applied to large data.</p>
      <p>But it doesn't fit the slide so I am going to show a miniature example.</p>
    </aside>
  </section>

  <section data-background="img/page_01.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_02.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_03.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>
</section>


<section>
  <h3><em>Background - Deduplication Performance</em></h3>
  <section>
    <div>
      <p>In 2017 we worked on a deduplication engine,<br/>and we tried to improve its performance.</p>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_16.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>The chunking part is Karp-Rabin, which is clearly bottleneck.</p>
      <p>Compared to SHA-1 which requires more algebric work, it is very costy in CPU time</p>
    </aside>
  </section>

  <!--section>
    <div>
      <p>Measureing the CPU usage of our system shows (GB/seconds):</p>
      <ol>
        <li>2.533 compressing with LZ4</li>
        <li>1.120 chunking with Buzzhash</li>
        <li>0.167 hashing with SHA-1</li>
        <li>0.150 everything else</li>
      </ol>
    </div>
  </section-->
</section>


<section>
  <h3><em>Chunking Problem</em></h3>
  <section>
    <div>
      <p>Given a stream of bytes, divide it into chunks for deduplication.</p>
      <ol>
        <li>Output identical chunks for identical data</li>
        <li>Good chunk size distribution.</li>
        <li>Good performance.</li>
        <li>Works for any input (photo, DB, text, random, etc...)</li>
      </ol>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>
</section>


<section>
  <h3><em>Traditional Solutions</em></h3>
  <section>
    <div>
      <p>Karp-Rabin</p>
      <p>Cyclic Polynomial</p>
    </div>
    <!-- NOTES -->
    <aside class="notes">
Explain the idea of splitting chunks by using some weak hash function.
And explain the benefits of rolling hash vs calculating hash per each window.
Show example of how it works with visual aids.
    </aside>
  </section>

  <section data-background="img/page_05.svg" data-background-size="60%"> <!-- data-background-transition="slide"-->
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_06.svg" data-background-size="60%"> <!-- data-background-transition="slide"-->
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>Computer CPU gives a <b>sequencial illusion</b></p>
      <p>When you have a condition it either predicts or caompute both branches</p>
    </aside>
  </section>

  <section data-background="img/page_07.svg" data-background-size="60%"> <!-- data-background-transition="slide"-->
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>CPU friendly intrinsics</p>
      <p>back a slide</p>
    </aside>
  </section>

  <section>
    <div>
<!--
$$h_i = \sum_{j=0}^{j=63} p^j x_{i-j} \mod N$$
$$h_{i+1} = p^{64} x_{i - 64} + p h _i + x_i \mod N$$

$$h_i = \bigoplus_{j=0}^{j=63} \text{rotate}(x_{i-j}, j)$$
$$h_{i+1} = x_{i - 64} + \text{rotate}(h _i, 1) + x_i$$
-->
      <table>
        <tr>
          <th align="center">Karp-Rabin</th>
          <th align="center">Cyclic Polynomial</th>
        </tr>
        <tr>
          <td><img src="img/kr01.png"></img></td>
          <td><img src="img/cp01.png"></img></td>
        </tr>
        <tr>
          <td><img src="img/kr02.png"></img></td>
          <td><img src="img/cp02.png"></img></td>
        </tr>
      </table>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>
</section>


<section>
  <h3><em>Proposed Solution</em></h3>
  <section>
    <div>
      <p><h4>How does it work:</h4></p>
      <ol>
        <li>Work with rolling vectors</li>
        <li>Calculate a hash of byte size</li>
        <li>
          Calculate the criteria, in a way that:
          <ul>
            <li>Number of calculations are constant<br/>
                unrelated to the vector size</li>
            <li>Can find a cutting point at a byte offset</li>
          </ul>
        </li>
      </ol>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_08.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>Notice the SIMD, and what it means</p>
      <p>We used regular CP</p>
    </aside>
  </section>

  <section data-background="img/page_09.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>Vector in, vector out</p>
      <p>Cast the input into 16-bit vectors, not good</p>
      <p>If per character, not good</p>
    </aside>
  </section>

  <section data-background="img/page_17a.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>The size of each hash is too samll.</p>
      <p>If we check of each offset is still per byte.</p>
    </aside>
  </section>

  <section data-background="img/page_17b.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_10.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_11.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section data-background="img/page_12.svg" data-background-size="60%">
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>soul of the algorithm.</p>
      <p>
    </aside>
  </section>
</section>


<section>
  <h3><em>Measured Results</em></h3>
  <section data-background="img/chunk-dist.png" data-background-size="60%">
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section>
    <div>
      <table>
        <tr>
          <th>Algorithm</th>
          <th>Random Data</th>
          <th>Corpus Data</th>
        </tr>
        <tr>
          <td>Karp-Rabin</td>
          <td>975 MB/s</td>
          <td>927 MB/s</td>
        </tr>
        <tr>
          <td>Cyclic-Polynomial</td>
          <td>1675 MB/s</td>
          <td>1676 MB/s</td>
        </tr>
        <tr>
          <td>Ours</td>
          <td>6715 MB/s</td>
          <td>7136 MB/s</td>
        </tr>
      </table>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>

  <section>
    <div>
      <table>
        <tr>
          <th>Chunking Alg.</th>
          <th><em>Dedup Perf.</em></th>
          <th>LZ4</th>
          <th>SHA1</th>
          <th>Other</th>
          <th>Chunking</th>
        </tr>
        <tr>
          <td>Karp-Rabin</td>
          <td><em>262 MB/s</em></td>
          <td>63.9%</td>
          <td>4.1%</td>
          <td>3.8%</td>
          <td>28.1%</td>
        </tr>
        <tr>
          <td>Ours</td>
          <td><em>345 MB/s</em></td>
          <td>84.5%</td>
          <td>5.4%</td>
          <td>5.1%</td>
          <td>4.7%</td>
        </tr>
      </table>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      <p>Notice how the chunking part shrinks.</p>
      <p>In many cases it makes fixed size solution less relevant.</p>
    </aside>
  </section>

  <section>
    <div>
      <ul>
        <li>Same Distribution</li>
        <li>Faster Chunking Performance</li>
        <li>Faster Overall Performance</li>
      </ul>
    </div>
    <div>
    </div>
    <!-- NOTES -->
    <aside class="notes">
      The SIMD notation exists for more than half a century now<br/>
      The intrinsics exsists for <b>TWO</b> decades<br/>
      But even in the past decade no product or group managed to break the CP performance<br/>
      It takes a minute or two to explain this algorithm<br/>
      If you are familiar with deduplication chunking<br/>
      But, it took a while and team work to figure it out<br/>
    </aside>
  </section>
</section>


<section>
  <h3><em>Future Work</em></h3>
  <section>
    <div>
      <em>A chunking algorithm that is</em><br/>
    </div>
    <div>
      <table>
        <tr>
          <th>*</th>
          <th>Past</th>
          <th>Presented</th>
          <th>Future</th>
        </tr>
        <tr>
          <th>Backward Compatible</th>
          <td> N/A </td>
          <td>f(k, x) &ne; f(l, x)</td>
          <td>f(k, x) = f(l, x)</td>
        </tr>
        <tr>
          <th>Work</th>
          <td>cn</td>
          <td>cn</td>
          <td>cn</td>
        </tr>
        <tr>
          <th>Speed</th>
          <td>cn</td>
          <td>c(n log k) / k</td>
          <td>c(n log k) / k</td>
        </tr>
      </table>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>
</section>


<section>
  <section>
    <div>
      <h1>Thanks</h1>
      <p><a href="https://github.com/dudejohnny/PSC2019">https://github.com/dudejohnny/PSC2019</a></p>
    </div>
    <!-- NOTES -->
    <aside class="notes">
    </aside>
  </section>
</section>


<!----------------------------------------------------------
  presentation end, back to the html part
------------------------------------------------------------>

      </div>
    </div>

    <script src="reveal.js/lib/js/head.min.js"></script>
    <script src="reveal.js/js/reveal.js"></script>
    <script>

      // More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        width: 1920,
        height: 1080,

        margin: 0.01,
        controls: true,
        progress: true,
        history: true,
        center: true,

        transition: 'slide', // none/fade/slide/convex/concave/zoom
        transitionSpeed: 'slow',
        backgroundTransition: 'slide', // none/fade/slide/convex/concave/zoom

    notes_pointer: {
        pointer: {
            size: 25,  // in pixels (scaled like the rest of reveal.js)
            color: 'rgba(255, 0, 0, 0.6)',  // something valid for css background-color
            key: 'A'
        },
        notes: {
            key: 'S'
        }
    },
        // More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'reveal.js/plugin/search/search.js', async: true },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
//          { src: 'reveal.js/plugin/notes/notes.js', async: true },
          { src: 'reveal.js/plugin/notes-pointer/notes-pointer.js', async: true }
        ]
      });

    </script>
  </body>
</html>
